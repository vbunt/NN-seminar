{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b7de43",
   "metadata": {},
   "source": [
    "### Валерия Бунтякова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c2bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from math import sqrt\n",
    "import torch\n",
    "from random import seed\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ba1d6",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed932648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('answers_subsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52cd5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}\n",
    "data.category = data.category.map(cat_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae118615",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = list('.,?!\"\\'\\\\/') + ['??', '???', '????', '!!', '!!!', '!!!!']\n",
    "\n",
    "def process_text(text):\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    # words = [word for word in words if word not in punctuation]\n",
    "    # сначала я убрала всю пунктуацию, а потом поняла что для нее всё равно нет векторов\n",
    "    # и в итоге она всё равно не используется\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638c005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f65282be98b43aba95379fe6e4d7c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=237779.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2freq = {}\n",
    "lengths = []\n",
    "\n",
    "for text in tqdm(data.text):\n",
    "    \n",
    "    words = process_text(text)\n",
    "    \n",
    "    lengths.append(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word in word2freq:\n",
    "            word2freq[word] += 1\n",
    "        else:\n",
    "            word2freq[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b72df39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd875f516b144cda3fd39b625bb5134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Read word2vec', max=2000000.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2index = {'PAD': 0}\n",
    "vectors = []\n",
    "    \n",
    "word2vec_file = open('cc.ru.300.vec')\n",
    "    \n",
    "n_words, embedding_dim = word2vec_file.readline().split()\n",
    "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
    "\n",
    "# Zero vector for PAD\n",
    "vectors.append(np.zeros((1, embedding_dim)))\n",
    "\n",
    "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
    "\n",
    "while True:\n",
    "\n",
    "    line = word2vec_file.readline().strip()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "        \n",
    "    current_parts = line.split()\n",
    "\n",
    "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
    "\n",
    "    if current_word in word2freq:\n",
    "\n",
    "        word2index[current_word] = len(word2index)\n",
    "\n",
    "        current_vectors = current_parts[-embedding_dim:]\n",
    "        current_vectors = np.array(list(map(float, current_vectors)))\n",
    "        current_vectors = np.expand_dims(current_vectors, 0)\n",
    "\n",
    "        vectors.append(current_vectors)\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "word2vec_file.close()\n",
    "\n",
    "vectors = np.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e614491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = y_data\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token]\n",
    "        \n",
    "        self.load(x_data, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "        words = [word for word in words if word not in punctuation]\n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for text in data_iterator:\n",
    "            \n",
    "            words = self.process_text(text)\n",
    "            \n",
    "            indexed_words = self.indexing(words)\n",
    "            \n",
    "            self.x_data.append(indexed_words)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        \n",
    "        if len(sequence)< self.sequence_length:\n",
    "            add_pad = self.sequence_length - len(sequence)\n",
    "            return sequence+[self.pad_index]*add_pad\n",
    "        else:\n",
    "            return sequence[:self.sequence_length]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "        \n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09a1279f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960bdd2ec6a14844a50c327d59c5f236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading data', max=214001.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258a5db11ed0483189aa24670e3453e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading data', max=23778.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
    "\n",
    "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47bb4b",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "065037a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_with_att(torch.nn.Module):\n",
    "    def __init__(self, matrix_w, n, lstm_size=256, linear_size=256, cnn_out_size=128, inner_linear_size=256): \n",
    "        #n - количество категорий\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.n = n\n",
    "\n",
    "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
    "\n",
    "        self.LSTM = torch.nn.LSTM(300, lstm_size, num_layers=2, batch_first=True, bidirectional=True) # 64 32 124\n",
    "        # задайте лстм, можно 2 уровня, лучше бидирекциональный\n",
    "        \n",
    "        \n",
    "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
    "        self.q_proj = torch.nn.Linear(in_features=2*lstm_size, out_features=linear_size)\n",
    "        self.k_proj = torch.nn.Linear(in_features=2*lstm_size, out_features=linear_size)\n",
    "        self.v_proj = torch.nn.Linear(in_features=2*lstm_size, out_features=linear_size)\n",
    "\n",
    "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
    "        \n",
    "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
    "        self.cnn_3gr = torch.nn.Conv1d(in_channels=linear_size, out_channels=cnn_out_size, kernel_size=3)\n",
    "        self.cnn_4gr = torch.nn.Conv1d(in_channels=linear_size, out_channels=cnn_out_size, kernel_size=4)\n",
    "        self.cnn_5gr = torch.nn.Conv1d(in_channels=linear_size, out_channels=cnn_out_size, kernel_size=5)\n",
    "        \n",
    "        # сверху накидываем два полносвязных слоя для классификации\n",
    "        self.linear_1 = torch.nn.Linear(in_features=3*cnn_out_size, out_features=inner_linear_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(in_features=inner_linear_size, out_features=n) \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb_layer(x)  # примените эмбеддинги\n",
    "        \n",
    "        x, _ = self.LSTM(x_emb)\n",
    "\n",
    "        # применим линейные преобразования для селф-эттеншена\n",
    "        x_q = self.q_proj(x) \n",
    "        x_k = self.k_proj(x)\n",
    "        x_v = self.v_proj(x) \n",
    "        \n",
    "        att_scores = torch.bmm(x_k, x_q.transpose(2, 1)) / sqrt(300)\n",
    "        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
    "        attention_vectors = torch.bmm(att_dist, x_v)\n",
    "\n",
    "        #транспонируем для конволюционных фильтров\n",
    "        x_att = attention_vectors.transpose(2,1) \n",
    "\n",
    "        x_cnn3 = self.cnn_3gr(x_att)\n",
    "        x_cnn4 = self.cnn_4gr(x_att)\n",
    "        x_cnn5 = self.cnn_5gr(x_att)\n",
    "\n",
    "        frst, _ = x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
    "        sc, _ = x_cnn4.max(dim= -1,)\n",
    "        thr, _ = x_cnn5.max(dim= -1,)\n",
    "\n",
    "        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
    "        \n",
    "        # пару полносвязных слоев с релу для классификации\n",
    "        x = self.linear_1(x_cat)\n",
    "        x = self.relu(x)    \n",
    "        x = self.linear_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9479654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters())\n",
    "\n",
    "    criterion = criterion.to(device)\n",
    "    epochs = 10\n",
    "    losses = []\n",
    "    best_test_loss = 10.\n",
    "\n",
    "    test_f1 = []\n",
    "\n",
    "    for n_epoch in range(epochs):\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        test_targets = []\n",
    "        test_pred_class = []\n",
    "\n",
    "        progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for x, y in train_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "\n",
    "            progress_bar.update(x.shape[0])\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for x, y in validation_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                pred = model(x)\n",
    "\n",
    "                pred = pred.cpu()\n",
    "\n",
    "                test_targets.append(y.numpy())\n",
    "                test_pred_class.append(np.argmax(pred, axis=1))\n",
    "\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "        test_targets = np.concatenate(test_targets).squeeze()\n",
    "        test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    "\n",
    "        f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
    "\n",
    "        test_f1.append(f1)\n",
    "\n",
    "#         print()\n",
    "#         print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "\n",
    "#         print('F1 test - {:.3f}'.format(f1))\n",
    "\n",
    "        # Early stopping:\n",
    "        if mean_test_loss < best_test_loss:\n",
    "            best_test_loss = mean_test_loss\n",
    "        else:\n",
    "            print('Early stopping')\n",
    "            print('F1 test - {:.3f}'.format(f1))\n",
    "            return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a9c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "n_classes = data.category.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f1b711a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11a2bcd89d141fcb61a2f9dafcb0129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adc24458f2442a980d7223e4c56a55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112517065281435faf5a38f772588b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039ad20ec6bc4f018928990a383bcbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb0dcfbac344f0995e55cd73e546ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping\n",
      "F1 test - 0.838\n"
     ]
    }
   ],
   "source": [
    "seed(13)\n",
    "model = model_with_att(vectors, n_classes)\n",
    "f1 = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfdb56",
   "metadata": {},
   "source": [
    "Дефолтная модель показывает f1-score 0.838. Попробуем подобрать гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8282493",
   "metadata": {},
   "source": [
    "## Гиперпараметры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cbbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'lstm_size':[128, 256, 512],\n",
    "        'linear_size':[128, 256, 512],\n",
    "        'cnn_out_size':[64, 128, 256],\n",
    "        'inner_linear_size':[64, 128, 256]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26877b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# я не знала как сделать это лучше... кринж\n",
    "pars = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            for h in range(3):\n",
    "                pars.append([grid['lstm_size'][i], \n",
    "                             grid['linear_size'][j], \n",
    "                             grid['cnn_out_size'][k], \n",
    "                             grid['inner_linear_size'][h]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84061a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_pars = choices(pars, k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ae2f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[128, 512, 256, 64],\n",
       " [128, 256, 256, 128],\n",
       " [256, 128, 128, 64],\n",
       " [256, 128, 128, 256],\n",
       " [128, 128, 128, 64],\n",
       " [128, 128, 256, 256],\n",
       " [512, 256, 64, 128],\n",
       " [128, 512, 64, 128],\n",
       " [128, 128, 128, 128],\n",
       " [256, 256, 64, 128],\n",
       " [512, 512, 64, 64],\n",
       " [128, 256, 64, 128],\n",
       " [512, 256, 64, 256],\n",
       " [256, 256, 256, 128],\n",
       " [512, 256, 128, 64],\n",
       " [128, 256, 256, 128],\n",
       " [128, 512, 64, 64],\n",
       " [256, 128, 256, 64],\n",
       " [512, 512, 64, 64],\n",
       " [128, 256, 256, 128],\n",
       " [512, 128, 128, 64],\n",
       " [256, 512, 256, 128],\n",
       " [128, 512, 64, 128],\n",
       " [256, 128, 256, 64],\n",
       " [512, 128, 64, 128],\n",
       " [512, 128, 64, 64],\n",
       " [256, 128, 128, 128],\n",
       " [128, 512, 64, 64],\n",
       " [128, 512, 256, 128],\n",
       " [256, 256, 256, 256],\n",
       " [128, 512, 128, 256],\n",
       " [256, 256, 256, 256],\n",
       " [128, 512, 256, 64],\n",
       " [512, 128, 256, 64],\n",
       " [256, 128, 64, 128],\n",
       " [512, 512, 256, 128],\n",
       " [128, 512, 128, 256],\n",
       " [128, 512, 128, 64],\n",
       " [256, 256, 256, 64],\n",
       " [512, 512, 64, 64]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9969bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(13)\n",
    "worked = []\n",
    "for p in tqdm(chosen_pars):\n",
    "    lstm_size = p[0]\n",
    "    linear_size = p[1]\n",
    "    cnn_out_size = p[2]\n",
    "    inner_linear_size = p[3]\n",
    "    model = model_with_att(vectors, \n",
    "                           n_classes, \n",
    "                           lstm_size=lstm_size, \n",
    "                           linear_size=linear_size, \n",
    "                           cnn_out_size=cnn_out_size,\n",
    "                           inner_linear_size=inner_linear_size)\n",
    "    \n",
    "    print('========== MODEL ===========')\n",
    "    print(lstm_size, linear_size, cnn_out_size, inner_linear_size)\n",
    "    f1 = train_model(model)\n",
    "    worked.append(f1)\n",
    "#     print(lstm_size, linear_size, cnn_out_size)\n",
    "    print('========== DONE ===========')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d782be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# я скрыла аутпут в предыдущей ячейке, потому что он слишкм длинный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27cbfafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worked.index(max(worked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2098518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8434266969467575"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worked[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98ae61f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 256, 256, 256]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_pars[31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb3f8c",
   "metadata": {},
   "source": [
    "Я выбрала по три возможных значения для каждого из гиперпараметров (дефолтное, в два раза больше и в два раза меньше). Всего получился 81 набор возможных значений. Из них я выбрала случайные 40 и посчитала, при каком наборе получается наибольший f1-score. Получилось 0.843 при [256, 256, 256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38cb644e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc974764e23404cbdb3acaa503519b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9070377ebdac48cea44562c08d7ae89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9367dda1f947d89c3fa4a295505e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f179370dbb4295b276bf658968b97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28709a348836424c8c9efa5f201fc85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e5423eb5e841a8a7429b6416b0e720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=214001.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping\n",
      "F1 test - 0.842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8417444696778535"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(13)\n",
    "model = model_with_att(vectors, \n",
    "                       n_classes, \n",
    "                       lstm_size=256, \n",
    "                       linear_size=256, \n",
    "                       cnn_out_size=256,\n",
    "                       inner_linear_size=256)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a46f0",
   "metadata": {},
   "source": [
    "Почему значение здесь и значение выше разные? Я не знаю, seed одинаковый(( Главное, что стало чуть-чуть лучше в любом случае. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
